{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import progressbar\n",
    "from multiprocessing import Pool\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(s):\n",
    "    return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_corpus(Dataset):\n",
    "    \"\"\"text corpus dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, base_dir='resources', tok_ind_files_list=['bijankhan_indexed.txt']):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tok_ind_files_list (list): .txt filenames, contains one sentence per line.\n",
    "            base_dir (string): directory with all the txt files.\n",
    "        \"\"\"\n",
    "        super(text_corpus, self).__init__()\n",
    "        self.ds = []\n",
    "        for i in tok_ind_files_list:\n",
    "            print('loading {} corpus...'.format(i))\n",
    "            self.load_txt(os.path.join(base_dir, i))\n",
    "\n",
    "    def load_txt(self, tok_ind_files_list):\n",
    "\n",
    "        with open(tok_ind_files_list) as f:\n",
    "            sentences = f.read().strip().split('\\n')\n",
    "\n",
    "        p = Pool(4)\n",
    "        bar = progressbar.ProgressBar()\n",
    "        for sentence in bar(sentences):\n",
    "            self.ds.append(p.map(to_int, sentence.split(' ')))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ds[idx]\n",
    "\n",
    "        return sample[:-1], sample[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    #torch.IntTensor(\n",
    "    B = len(batch)\n",
    "    T = max([len(i[0]) for i in batch])\n",
    "    in_batch, out_batch = torch.ones((T, B)).long(), torch.ones((T, B)).long()\n",
    "    for i in range(B):\n",
    "        l = len(batch[i][0])\n",
    "        in_batch[0:l, i] = torch.LongTensor(batch[i][0])\n",
    "        out_batch[0:l, i] = torch.LongTensor(batch[i][1])\n",
    "    #print('in_batch:', in_batch)\n",
    "    #print('out_batch:', out_batch)\n",
    "    return in_batch, out_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, ntoken, bsz, nembd=128, nhid=256):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.nhid = nhid\n",
    "        self.bsz = bsz\n",
    "        self.nembd = nembd\n",
    "        self.drop = nn.Dropout(.1)\n",
    "        self.encoder = nn.Embedding(ntoken, nembd)\n",
    "        self.rnn = nn.LSTM(nembd, nhid, dropout=.1)\n",
    "        self.fc = nn.Linear(nhid, nembd)\n",
    "        self.decoder = nn.Linear(nembd, ntoken)\n",
    "        self.decoder.weight = self.encoder.weight\n",
    "        self.init_weights()\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        T = x.shape[0]\n",
    "        emb = self.drop(self.encoder(x))\n",
    "        #print('emb size: {}'.format(emb.size()))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        #print('output size: {}'.format(output.size()))\n",
    "        dropped_output = self.drop(output)\n",
    "        #print('dropped_output size: {}'.format(dropped_output.size()))\n",
    "        dropped_fc = self.drop(self.fc(dropped_output.view(T * self.bsz, -1)))\n",
    "        #print('dropped_fc size: {}'.format(dropped_fc.size()))\n",
    "        decoded = self.decoder(dropped_fc.view(T * self.bsz, -1))\n",
    "        #print('decoded size: {}'.format(decoded.size()))\n",
    "        return decoded.view(T, self.bsz, -1), hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1, self.bsz, self.nhid)), Variable(torch.zeros(1, self.bsz, self.nhid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data.zero_())\n",
    "        #return Variable(h.data).cuda(device_id)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading bijankhan_indexed.txt corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1001 of 1001) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------epoch001----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% (127 of 1001) |##                    | Elapsed Time: 0:00:11 ETA:  0:01:16/usr/local/lib/python3.5/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type RNNModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # CONSTANTS\n",
    "    mb_size = 1\n",
    "    update_size = 128\n",
    "    ntoken = 48603\n",
    "    t0 = time.time()\n",
    "    lr = .001\n",
    "\n",
    "    tc = text_corpus()\n",
    "    dataloader = DataLoader(tc, \n",
    "                            collate_fn=my_collate, \n",
    "                            batch_size=mb_size, \n",
    "                            shuffle=True, \n",
    "                            num_workers=2, \n",
    "                            drop_last=True)\n",
    "    model = RNNModel(ntoken, mb_size)\n",
    "    #model.cuda()\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter('log')\n",
    "\n",
    "    counter = 0\n",
    "    for epoch in range(1):\n",
    "        print('-' * 40 + 'epoch{:03d}'.format(epoch + 1) + '-' * 40)\n",
    "\n",
    "        bar = progressbar.ProgressBar()\n",
    "        for ind, io_seqs in enumerate(bar(dataloader)):\n",
    "            model.zero_grad()\n",
    "            t = io_seqs[1].shape[1]\n",
    "            #in_seq, out_seq = Variable(io_seqs[0]).cuda(), Variable(io_seqs[1]).cuda()\n",
    "            in_seq, out_seq = Variable(io_seqs[0]), Variable(io_seqs[1])\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            model_score, hidden = model(in_seq, hidden)\n",
    "            loss = loss_function(model_score.view(-1, ntoken), out_seq.view(-1))\n",
    "            loss.backward()\n",
    "            writer.add_scalar('data/loss', loss.data[0], counter)\n",
    "            counter += 1\n",
    "            if ind % update_size == update_size - 1:\n",
    "                optimizer.step()\n",
    "                break\n",
    "\n",
    "        # save model\n",
    "        with open(os.path.join('garbage_model', 'model_{:03d}.mdl'.format(epoch)), 'wb') as f:\n",
    "            torch.save(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
